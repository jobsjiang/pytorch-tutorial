{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/github/GokuMohandas/practicalAI/blob/master/notebooks/15_Computer_Vision.ipynb#scrollTo=NcufVLErvKCt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "config = {\n",
    "  \"seed\": 1234,\n",
    "  \"cuda\": True,\n",
    "  \"data_url\": \"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/data/surnames.csv\",\n",
    "  \"data_dir\": \"cifar10\",\n",
    "  \"shuffle\": True,\n",
    "  \"train_size\": 0.7,\n",
    "  \"val_size\": 0.15,\n",
    "  \"test_size\": 0.15,\n",
    "  \"vectorizer_file\": \"vectorizer.json\",\n",
    "  \"model_file\": \"model.pth\",\n",
    "  \"save_dir\": \"experiments\",\n",
    "  \"num_epochs\": 5,\n",
    "  \"early_stopping_criteria\": 5,\n",
    "  \"learning_rate\": 1e-3,\n",
    "  \"batch_size\": 128,\n",
    "  \"fc\": {\n",
    "    \"hidden_dim\": 100,\n",
    "    \"dropout_p\": 0.1\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed, cuda):\n",
    "    \"\"\" Set Numpy and PyTorch seeds.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    print (\"==> ðŸŒ± Set NumPy and PyTorch seeds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique_id():\n",
    "    \"\"\"Generate a unique uuid\n",
    "    preceded by a epochtime.\n",
    "    \"\"\"\n",
    "    timestamp = int(time.time())\n",
    "    unique_id = \"{}_{}\".format(timestamp, uuid.uuid1())\n",
    "    print (\"==> ðŸ”‘ Generated unique id: {0}\".format(unique_id))\n",
    "    return unique_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dirs(dirpath):\n",
    "    \"\"\"Creating directories.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "        print (\"==> ðŸ“‚ Created {0}\".format(dirpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cuda(cuda):\n",
    "    \"\"\"Check to see if GPU is available.\n",
    "    \"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        cuda = False\n",
    "    device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "    print (\"==> ðŸ’» Device: {0}\".format(device))\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> ðŸŒ± Set NumPy and PyTorch seeds.\n"
     ]
    }
   ],
   "source": [
    "# Set seeds for reproducability\n",
    "set_seeds(seed=config[\"seed\"], cuda=config[\"cuda\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> ðŸ”‘ Generated unique id: 1564135311_63c17570-af8c-11e9-ab8a-04d4c400932f\n"
     ]
    }
   ],
   "source": [
    "# Generate unique experiment ID\n",
    "config[\"experiment_id\"] = generate_unique_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> ðŸ“‚ Created experiments\\1564135311_63c17570-af8c-11e9-ab8a-04d4c400932f\n"
     ]
    }
   ],
   "source": [
    "# Create experiment directory\n",
    "config[\"save_dir\"] = os.path.join(config[\"save_dir\"], config[\"experiment_id\"])\n",
    "create_dirs(dirpath=config[\"save_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded filepaths: \n",
      "experiments\\1564135311_63c17570-af8c-11e9-ab8a-04d4c400932f\\vectorizer.json\n",
      "experiments\\1564135311_63c17570-af8c-11e9-ab8a-04d4c400932f\\model.pth\n"
     ]
    }
   ],
   "source": [
    "# Expand file paths to store components later\n",
    "config[\"vectorizer_file\"] = os.path.join(config[\"save_dir\"], config[\"vectorizer_file\"])\n",
    "config[\"model_file\"] = os.path.join(config[\"save_dir\"], config[\"model_file\"])\n",
    "print (\"Expanded filepaths: \")\n",
    "print (\"{}\".format(config[\"vectorizer_file\"]))\n",
    "print (\"{}\".format(config[\"model_file\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save config\n",
    "config_fp = os.path.join(config[\"save_dir\"], \"config.json\")\n",
    "with open(config_fp, \"w\") as fp:\n",
    "    json.dump(config, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> ðŸ’» Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check CUDA\n",
    "config[\"device\"] = check_cuda(cuda=config[\"cuda\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jianghaitao1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\"Get CIFAR10 data.\n",
    "    \"\"\"\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    X = np.vstack([x_train, x_test])\n",
    "    y = np.vstack([y_train, y_test]).squeeze(1)\n",
    "    print (\"==> ðŸŒŠ Downloading Cifar10 data using TensorFlow.\")\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_class_dirs(data_dir, classes):\n",
    "    \"\"\"Create class directories.\n",
    "    \"\"\"\n",
    "    create_dirs(dirpath=data_dir)\n",
    "    for _class in classes.values():\n",
    "        classpath = os.path.join(data_dir, _class)\n",
    "        create_dirs(dirpath=classpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(data_dir, classes):\n",
    "    \"\"\"Visualize sample images for\n",
    "    each class.\n",
    "    \"\"\"\n",
    "    # Visualize some samples\n",
    "    num_samples = len(classes)\n",
    "    for i, _class in enumerate(classes.values()):  \n",
    "        for file in os.listdir(os.path.join(data_dir, _class)):\n",
    "            if file.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                plt.subplot(1, num_samples, i+1)\n",
    "                plt.title(\"{0}\".format(_class))\n",
    "                img = Image.open(os.path.join(data_dir, _class, file))\n",
    "                plt.imshow(img)\n",
    "                plt.axis(\"off\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_array(fp):\n",
    "    \"\"\"Conver image file to NumPy array.\n",
    "    \"\"\"\n",
    "    img = Image.open(fp)\n",
    "    array = np.asarray(img, dtype=\"float32\")\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, classes):\n",
    "    \"\"\"Load data into Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    # Load data from files\n",
    "    data = []\n",
    "    for i, _class in enumerate(classes.values()):  \n",
    "        for file in os.listdir(os.path.join(data_dir, _class)):\n",
    "            if file.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                full_filepath = os.path.join(data_dir, _class, file)\n",
    "                data.append({\"image\": img_to_array(full_filepath), \"category\": _class})\n",
    "                \n",
    "    # Load to Pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    print (\"==> ðŸ–¼ï¸ Image dimensions: {0}\".format(df.image[0].shape))\n",
    "    print (\"==> ðŸ£ Raw data:\")\n",
    "    print (df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 310s 2us/step\n",
      "==> ðŸŒŠ Downloading Cifar10 data using TensorFlow.\n",
      "X: (60000, 32, 32, 3)\n",
      "y: (60000,)\n"
     ]
    }
   ],
   "source": [
    "# Get CIFAR10 data\n",
    "X, y = get_data()\n",
    "print (\"X:\", X.shape)\n",
    "print (\"y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes\n",
    "classes = {0: 'plane', 1: 'car', 2: 'bird', 3: 'cat', 4: 'deer', 5: 'dog', \n",
    "           6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> ðŸ“‚ Created cifar10\n",
      "==> ðŸ“‚ Created cifar10\\plane\n",
      "==> ðŸ“‚ Created cifar10\\car\n",
      "==> ðŸ“‚ Created cifar10\\bird\n",
      "==> ðŸ“‚ Created cifar10\\cat\n",
      "==> ðŸ“‚ Created cifar10\\deer\n",
      "==> ðŸ“‚ Created cifar10\\dog\n",
      "==> ðŸ“‚ Created cifar10\\frog\n",
      "==> ðŸ“‚ Created cifar10\\horse\n",
      "==> ðŸ“‚ Created cifar10\\ship\n",
      "==> ðŸ“‚ Created cifar10\\truck\n"
     ]
    }
   ],
   "source": [
    "# Create image directories\n",
    "create_class_dirs(data_dir=config[\"data_dir\"], classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save images for each class\n",
    "for i, (image, label) in enumerate(zip(X, y)):\n",
    "    _class = classes[label]\n",
    "    im = Image.fromarray(image)\n",
    "    im.save(os.path.join(config[\"data_dir\"], _class, \"{0:02d}.png\".format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize each class\n",
    "visualize_samples(data_dir=config[\"data_dir\"], classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> ðŸ–¼ï¸ Image dimensions: (32, 32, 3)\n",
      "==> ðŸ£ Raw data:\n",
      "  category                                              image\n",
      "0    plane  [[[219.0, 238.0, 245.0], [219.0, 238.0, 245.0]...\n",
      "1    plane  [[[115.0, 138.0, 191.0], [118.0, 141.0, 193.0]...\n",
      "2    plane  [[[145.0, 153.0, 155.0], [147.0, 156.0, 161.0]...\n",
      "3    plane  [[[126.0, 133.0, 149.0], [124.0, 131.0, 147.0]...\n",
      "4    plane  [[[71.0, 134.0, 193.0], [70.0, 133.0, 192.0], ...\n"
     ]
    }
   ],
   "source": [
    "# Load data into DataFrame\n",
    "df = load_data(data_dir=config[\"data_dir\"], classes=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, shuffle, train_size, val_size, test_size):\n",
    "    \"\"\"Split the data into train/val/test splits.\n",
    "    \"\"\"\n",
    "    # Split by category\n",
    "    by_category = collections.defaultdict(list)\n",
    "    for _, row in df.iterrows():\n",
    "        by_category[row.category].append(row.to_dict())\n",
    "    print (\"\\n==> ðŸ›ï¸ Categories:\")\n",
    "    for category in by_category:\n",
    "        print (\"{0}: {1}\".format(category, len(by_category[category])))\n",
    "\n",
    "    # Create split data\n",
    "    final_list = []\n",
    "    for _, item_list in sorted(by_category.items()):\n",
    "        if shuffle:\n",
    "            np.random.shuffle(item_list)\n",
    "        n = len(item_list)\n",
    "        n_train = int(train_size*n)\n",
    "        n_val = int(val_size*n)\n",
    "        n_test = int(test_size*n)\n",
    "\n",
    "      # Give data point a split attribute\n",
    "        for item in item_list[:n_train]:\n",
    "            item['split'] = 'train'\n",
    "        for item in item_list[n_train:n_train+n_val]:\n",
    "            item['split'] = 'val'\n",
    "        for item in item_list[n_train+n_val:]:\n",
    "            item['split'] = 'test'\n",
    "\n",
    "        # Add to final list\n",
    "        final_list.extend(item_list)\n",
    "\n",
    "    # df with split datasets\n",
    "    split_df = pd.DataFrame(final_list)\n",
    "    print (\"\\n==> ðŸ–– Splits:\")\n",
    "    print (split_df[\"split\"].value_counts())\n",
    "\n",
    "    return split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> ðŸ›ï¸ Categories:\n",
      "plane: 6000\n",
      "car: 6000\n",
      "bird: 6000\n",
      "cat: 6000\n",
      "deer: 6000\n",
      "dog: 6000\n",
      "frog: 6000\n",
      "horse: 6000\n",
      "ship: 6000\n",
      "truck: 6000\n",
      "\n",
      "==> ðŸ–– Splits:\n",
      "train    42000\n",
      "test      9000\n",
      "val       9000\n",
      "Name: split, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "split_df = split_data(\n",
    "    df=df, shuffle=config[\"shuffle\"],\n",
    "    train_size=config[\"train_size\"],\n",
    "    val_size=config[\"val_size\"],\n",
    "    test_size=config[\"test_size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\"):\n",
    "\n",
    "        # Token to index\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self.token_to_idx = token_to_idx\n",
    "\n",
    "        # Index to token\n",
    "        self.idx_to_token = {idx: token \\\n",
    "                             for token, idx in self.token_to_idx.items()}\n",
    "        \n",
    "        # Add unknown token\n",
    "        self.add_unk = add_unk\n",
    "        self.unk_token = unk_token\n",
    "        if self.add_unk:\n",
    "            self.unk_index = self.add_token(self.unk_token)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        return {'token_to_idx': self.token_to_idx,\n",
    "                'add_unk': self.add_unk, 'unk_token': self.unk_token}\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        return cls(**contents)\n",
    "\n",
    "    def add_token(self, token):\n",
    "        if token in self.token_to_idx:\n",
    "            index = self.token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self.token_to_idx)\n",
    "            self.token_to_idx[token] = index\n",
    "            self.idx_to_token[index] = token\n",
    "        return index\n",
    "\n",
    "    def add_tokens(self, tokens):\n",
    "        return [self.add_token[token] for token in tokens]\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        if self.add_unk:\n",
    "            index = self.token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            index =  self.token_to_idx[token]\n",
    "        return index\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        if index not in self.idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self.idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Vocabulary(size=10)>\n",
      "10\n",
      "2\n",
      "bird\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary instance\n",
    "category_vocab = Vocabulary(add_unk=False)\n",
    "for index, row in df.iterrows():\n",
    "    category_vocab.add_token(row.category)\n",
    "print (category_vocab) # __str__\n",
    "print (len(category_vocab)) # __len__\n",
    "index = category_vocab.lookup_token(\"bird\")\n",
    "print (index)\n",
    "print (category_vocab.lookup_index(index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceVocabulary(Vocabulary):\n",
    "    def __init__(self, train_means, train_stds):\n",
    "        \n",
    "        self.train_means = train_means\n",
    "        self.train_stds = train_stds\n",
    "        \n",
    "    def to_serializable(self):\n",
    "        contents = {'train_means': self.train_means,\n",
    "                    'train_stds': self.train_stds}\n",
    "        return contents\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, df):\n",
    "        train_data = df[df.split == \"train\"]\n",
    "        means = {0:[], 1:[], 2:[]}\n",
    "        stds = {0:[], 1:[], 2:[]}\n",
    "        for image in train_data.image:\n",
    "            for dim in range(3):\n",
    "                means[dim].append(np.mean(image[:, :, dim]))\n",
    "                stds[dim].append(np.std(image[:, :, dim]))\n",
    "        train_means = np.array((np.mean(means[0]), np.mean(means[1]), \n",
    "                                np.mean(means[2])), dtype=\"float64\").tolist()\n",
    "        train_stds = np.array((np.mean(stds[0]), np.mean(stds[1]), \n",
    "                               np.mean(stds[2])), dtype=\"float64\").tolist()\n",
    "            \n",
    "        return cls(train_means, train_stds)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"<SequenceVocabulary(train_means: {0}, train_stds: {1}>\".format(\n",
    "            self.train_means, self.train_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SequenceVocabulary(train_means: [125.49060821533203, 123.18034362792969, 114.1384506225586], train_stds: [51.59408187866211, 50.860694885253906, 51.29096984863281]>\n"
     ]
    }
   ],
   "source": [
    "# Create SequenceVocabulary instance\n",
    "image_vocab = SequenceVocabulary.from_dataframe(split_df)\n",
    "print (image_vocab) # __str__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageVectorizer(object):\n",
    "    def __init__(self, image_vocab, category_vocab):\n",
    "        self.image_vocab = image_vocab\n",
    "        self.category_vocab = category_vocab\n",
    "\n",
    "    def vectorize(self, image):\n",
    "        # Avoid modifying the actual df\n",
    "        image = np.copy(image)\n",
    "        \n",
    "        # Normalize\n",
    "        for dim in range(3):\n",
    "            mean = self.image_vocab.train_means[dim]\n",
    "            std = self.image_vocab.train_stds[dim]\n",
    "            image[:, :, dim] = ((image[:, :, dim] - mean) / std)\n",
    "            \n",
    "        # Reshape from (32, 32, 3) to (3, 32, 32)\n",
    "        image = np.swapaxes(image, 0, 2)\n",
    "        image = np.swapaxes(image, 1, 2)\n",
    "                \n",
    "        return image\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, df):\n",
    "        # Create vocabularies\n",
    "        image_vocab = SequenceVocabulary.from_dataframe(df)\n",
    "        category_vocab = Vocabulary(add_unk=False)   \n",
    "        for category in sorted(set(df.category)):\n",
    "            category_vocab.add_token(category)\n",
    "        return cls(image_vocab, category_vocab)\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        image_vocab = SequenceVocabulary.from_serializable(contents['image_vocab'])\n",
    "        category_vocab = Vocabulary.from_serializable(contents['category_vocab'])\n",
    "        return cls(image_vocab=image_vocab, \n",
    "                   category_vocab=category_vocab)\n",
    "    \n",
    "    def to_serializable(self):\n",
    "        return {'image_vocab': self.image_vocab.to_serializable(),\n",
    "                'category_vocab': self.category_vocab.to_serializable()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SequenceVocabulary(train_means: [125.49060821533203, 123.18034362792969, 114.1384506225586], train_stds: [51.59408187866211, 50.860694885253906, 51.29096984863281]>\n",
      "<Vocabulary(size=10)>\n",
      "{'bird': 0, 'car': 1, 'cat': 2, 'deer': 3, 'dog': 4, 'frog': 5, 'horse': 6, 'plane': 7, 'ship': 8, 'truck': 9}\n",
      "(3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# Vectorizer instance\n",
    "vectorizer = ImageVectorizer.from_dataframe(split_df)\n",
    "print (vectorizer.image_vocab)\n",
    "print (vectorizer.category_vocab)\n",
    "print (vectorizer.category_vocab.token_to_idx)\n",
    "image_vector = vectorizer.vectorize(split_df.iloc[0].image)\n",
    "print (image_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, vectorizer, infer=False):\n",
    "        self.df = df\n",
    "        self.vectorizer = vectorizer\n",
    "        \n",
    "        # Data splits\n",
    "        if not infer:\n",
    "            self.train_df = self.df[self.df.split=='train']\n",
    "            self.train_size = len(self.train_df)\n",
    "            self.val_df = self.df[self.df.split=='val']\n",
    "            self.val_size = len(self.val_df)\n",
    "            self.test_df = self.df[self.df.split=='test']\n",
    "            self.test_size = len(self.test_df)\n",
    "            self.lookup_dict = {'train': (self.train_df, self.train_size), \n",
    "                                'val': (self.val_df, self.val_size),\n",
    "                                'test': (self.test_df, self.test_size)}\n",
    "            self.set_split('train')\n",
    "\n",
    "            # Class weights (for imbalances)\n",
    "            class_counts = df.category.value_counts().to_dict()\n",
    "            def sort_key(item):\n",
    "                return self.vectorizer.category_vocab.lookup_token(item[0])\n",
    "            sorted_counts = sorted(class_counts.items(), key=sort_key)\n",
    "            frequencies = [count for _, count in sorted_counts]\n",
    "            self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n",
    "        elif infer:\n",
    "            self.infer_df = self.df[self.df.split==\"infer\"]\n",
    "            self.infer_size = len(self.infer_df)\n",
    "            self.lookup_dict = {'infer': (self.infer_df, self.infer_size)}\n",
    "            self.set_split('infer')\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, df):\n",
    "        train_df = df[df.split=='train']\n",
    "        return cls(df, ImageVectorizer.from_dataframe(train_df))\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_load_vectorizer(cls, df, vectorizer_filepath):\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
    "        return cls(df, vectorizer)\n",
    "\n",
    "    def load_vectorizer_only(vectorizer_filepath):\n",
    "        with open(vectorizer_filepath) as fp:\n",
    "            return ImageVectorizer.from_serializable(json.load(fp))\n",
    "\n",
    "    def save_vectorizer(self, vectorizer_filepath):\n",
    "        with open(vectorizer_filepath, \"w\") as fp:\n",
    "            json.dump(self.vectorizer.to_serializable(), fp)\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        self.target_split = split\n",
    "        self.target_df, self.target_size = self.lookup_dict[split]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Dataset(split={0}, size={1})\".format(\n",
    "            self.target_split, self.target_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.target_df.iloc[index]\n",
    "        image_vector = self.vectorizer.vectorize(row.image)\n",
    "        category_index = self.vectorizer.category_vocab.lookup_token(row.category)\n",
    "        return {'image': image_vector, \n",
    "                'category': category_index}\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "        return len(self) // batch_size\n",
    "\n",
    "    def generate_batches(self, batch_size, shuffle=True, drop_last=True, device=\"cpu\"):\n",
    "        dataloader = DataLoader(dataset=self, batch_size=batch_size, \n",
    "                                shuffle=shuffle, drop_last=drop_last)\n",
    "        for data_dict in dataloader:\n",
    "            out_data_dict = {}\n",
    "            for name, tensor in data_dict.items():\n",
    "                out_data_dict[name] = data_dict[name].to(device)\n",
    "            yield out_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(dataset):\n",
    "    \"\"\"Some sanity checks on the dataset.\n",
    "    \"\"\"\n",
    "    sample_idx = random.randint(0,len(dataset))\n",
    "    sample = dataset[sample_idx]\n",
    "    print (\"\\n==> ðŸ”¢ Dataset:\")\n",
    "    print (\"Random sample: {0}\".format(sample))\n",
    "    print (\"Unvectorized category: {0}\".format(\n",
    "        dataset.vectorizer.category_vocab.lookup_index(sample['category'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002])\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and vectorizer\n",
    "dataset = ImageDataset.load_dataset_and_make_vectorizer(split_df)\n",
    "dataset.save_vectorizer(config[\"vectorizer_file\"])\n",
    "vectorizer = dataset.vectorizer\n",
    "print (dataset.class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> ðŸ”¢ Dataset:\n",
      "Random sample: {'image': array([[[-2.1996827 , -1.8895696 , -1.6376027 , ..., -2.005862  ,\n",
      "         -2.0640082 , -1.7538952 ],\n",
      "        [-2.1415365 , -1.9670979 , -1.5600744 , ..., -1.3274896 ,\n",
      "         -1.2887255 , -1.3468717 ],\n",
      "        [-2.0833902 , -2.0446262 , -1.7732772 , ..., -1.2305793 ,\n",
      "         -0.93984824, -1.5794564 ],\n",
      "        ...,\n",
      "        [ 0.14554754, -0.47467864, -1.7926593 , ...,  0.6107172 ,\n",
      "          0.55257094,  0.5913351 ],\n",
      "        [ 0.20369375, -0.06765521, -0.7847917 , ...,  0.92083025,\n",
      "          0.74639165,  0.57195306],\n",
      "        [ 0.28122202,  0.1067834 ,  0.0486372 , ...,  0.9789765 ,\n",
      "          0.95959437,  0.7657737 ]],\n",
      "\n",
      "       [[-1.9893622 , -1.6157928 , -1.301208  , ..., -1.6747774 ,\n",
      "         -1.6157928 , -1.3208696 ],\n",
      "        [-1.9500391 , -1.6944389 , -1.2225618 , ..., -1.0652695 ,\n",
      "         -0.90797704, -0.9669617 ],\n",
      "        [-1.8910545 , -1.7927467 , -1.4388388 , ..., -0.9669617 ,\n",
      "         -0.59339225, -1.2225618 ],\n",
      "        ...,\n",
      "        [ 0.37002358, -0.20016132, -1.517485  , ...,  0.5863006 ,\n",
      "          0.5469775 ,  0.5863006 ],\n",
      "        [ 0.40934667,  0.17340809, -0.5344076 , ...,  0.95987004,\n",
      "          0.8025776 ,  0.6256237 ],\n",
      "        [ 0.40934667,  0.27171585,  0.23239274, ...,  1.0778393 ,\n",
      "          1.0581777 ,  0.8615623 ]],\n",
      "\n",
      "       [[-2.0888364 , -1.718401  , -1.4064552 , ..., -1.2894756 ,\n",
      "         -1.2504823 , -0.89954334],\n",
      "        [-2.0108502 , -1.7963873 , -1.3674619 , ..., -0.37313488,\n",
      "         -0.25615525, -0.3926315 ],\n",
      "        [-1.8938705 , -1.8743738 , -1.6209179 , ..., -0.41212812,\n",
      "         -0.11967897, -0.84105355],\n",
      "        ...,\n",
      "        [ 0.6601854 ,  0.19226678, -0.97752976, ...,  1.1476007 ,\n",
      "          1.0891109 ,  1.0891109 ],\n",
      "        [ 0.6406888 ,  0.54320574, -0.00269932, ...,  1.4985396 ,\n",
      "          1.3035735 ,  1.0501176 ],\n",
      "        [ 0.56270236,  0.6016956 ,  0.7381718 , ...,  1.5570295 ,\n",
      "          1.4985396 ,  1.225587  ]]], dtype=float32), 'category': 9}\n",
      "Unvectorized category: truck\n"
     ]
    }
   ],
   "source": [
    "# Sample checks\n",
    "sample(dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageModel(nn.Module):\n",
    "    def __init__(self, num_hidden_units, num_classes, dropout_p):\n",
    "        super(ImageModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5) # input_channels:3, output_channels:10 (aka num filters)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) \n",
    "        self.conv_dropout = nn.Dropout2d(dropout_p)\n",
    "        self.fc1 = nn.Linear(20*5*5, num_hidden_units)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc2 = nn.Linear(num_hidden_units, num_classes)\n",
    "\n",
    "    def forward(self, x, apply_softmax=False):\n",
    "        # Conv pool\n",
    "        z = self.conv1(x) # (N, 10, 28, 28)\n",
    "        z = F.max_pool2d(z, 2) # (N, 10, 14, 14)\n",
    "        z = F.relu(z)\n",
    "        \n",
    "        # Conv pool\n",
    "        z = self.conv2(z) # (N, 20, 10, 10)\n",
    "        z = self.conv_dropout(z) \n",
    "        z = F.max_pool2d(z, 2) # (N, 20, 5, 5)\n",
    "        z = F.relu(z)\n",
    "        \n",
    "        # Flatten\n",
    "        z = z.view(-1, 20*5*5)\n",
    "        \n",
    "        # FC\n",
    "        z = F.relu(self.fc1(z))\n",
    "        z = self.dropout(z)\n",
    "        y_pred = self.fc2(z)\n",
    "        \n",
    "        if apply_softmax:\n",
    "            y_pred = F.softmax(y_pred, dim=1)\n",
    "        return y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(config, vectorizer):\n",
    "    \"\"\"Initialize the model.\n",
    "    \"\"\"\n",
    "    print (\"\\n==> ðŸš€ Initializing model:\")\n",
    "    model = ImageModel(\n",
    "       num_hidden_units=config[\"fc\"][\"hidden_dim\"], \n",
    "       num_classes=len(vectorizer.category_vocab),\n",
    "       dropout_p=config[\"fc\"][\"dropout_p\"])\n",
    "    print (model.named_modules)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> ðŸš€ Initializing model:\n",
      "<bound method Module.named_modules of ImageModel(\n",
      "  (conv1): Conv2d(3, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv_dropout): Dropout2d(p=0.1)\n",
      "  (fc1): Linear(in_features=500, out_features=100, bias=True)\n",
      "  (dropout): Dropout(p=0.1)\n",
      "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "model = initialize_model(config=config, vectorizer=vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_pred, y_target):\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_train_state(model, train_state):\n",
    "    \"\"\" Update train state during training.\n",
    "    \"\"\"\n",
    "    # Verbose\n",
    "    print (\"[EPOCH]: {0} | [LR]: {1} | [TRAIN LOSS]: {2:.2f} | [TRAIN ACC]: {3:.1f}% | [VAL LOSS]: {4:.2f} | [VAL ACC]: {5:.1f}%\".format(\n",
    "      train_state['epoch_index'], train_state['learning_rate'], \n",
    "        train_state['train_loss'][-1], train_state['train_acc'][-1], \n",
    "        train_state['val_loss'][-1], train_state['val_acc'][-1]))\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "\n",
    "        # If loss worsened\n",
    "        if loss_t >= train_state['early_stopping_best_val']:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = train_state['early_stopping_step'] \\\n",
    "          >= train_state['early_stopping_criteria']\n",
    "    return train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, dataset, model, model_file, device, shuffle, \n",
    "               num_epochs, batch_size, learning_rate, early_stopping_criteria):\n",
    "        self.dataset = dataset\n",
    "        self.class_weights = dataset.class_weights.to(device)\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.shuffle = shuffle\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.loss_func = nn.CrossEntropyLoss(self.class_weights)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer=self.optimizer, mode='min', factor=0.5, patience=1)\n",
    "        self.train_state = {\n",
    "            'done_training': False,\n",
    "            'stop_early': False, \n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'early_stopping_criteria': early_stopping_criteria,\n",
    "            'learning_rate': learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': model_file}\n",
    "  \n",
    "    def run_train_loop(self):\n",
    "        print (\"==> ðŸ‹ Training:\")\n",
    "        for epoch_index in range(self.num_epochs):\n",
    "            self.train_state['epoch_index'] = epoch_index\n",
    "      \n",
    "            # Iterate over train dataset\n",
    "\n",
    "            # initialize batch generator, set loss and acc to 0, set train mode on\n",
    "            self.dataset.set_split('train')\n",
    "            batch_generator = self.dataset.generate_batches(\n",
    "                batch_size=self.batch_size, shuffle=self.shuffle, \n",
    "                device=self.device)\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "            self.model.train()\n",
    "\n",
    "            for batch_index, batch_dict in enumerate(batch_generator):\n",
    "                # zero the gradients\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # compute the output\n",
    "                y_pred = self.model(batch_dict['image'])\n",
    "\n",
    "                # compute the loss\n",
    "                loss = self.loss_func(y_pred, batch_dict['category'])\n",
    "                loss_t = loss.item()\n",
    "                running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "                # compute gradients using loss\n",
    "                loss.backward()\n",
    "\n",
    "                # use optimizer to take a gradient step\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                # compute the accuracy\n",
    "                acc_t = compute_accuracy(y_pred, batch_dict['category'])\n",
    "                running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            self.train_state['train_loss'].append(running_loss)\n",
    "            self.train_state['train_acc'].append(running_acc)\n",
    "\n",
    "            # Iterate over val dataset\n",
    "\n",
    "            # initialize batch generator, set loss and acc to 0; set eval mode on\n",
    "            self.dataset.set_split('val')\n",
    "            batch_generator = self.dataset.generate_batches(\n",
    "                batch_size=self.batch_size, shuffle=self.shuffle, device=self.device)\n",
    "            running_loss = 0.\n",
    "            running_acc = 0.\n",
    "            self.model.eval()\n",
    "\n",
    "            for batch_index, batch_dict in enumerate(batch_generator):\n",
    "\n",
    "                # compute the output\n",
    "                y_pred =  self.model(batch_dict['image'])\n",
    "\n",
    "                # compute the loss\n",
    "                loss = self.loss_func(y_pred, batch_dict['category'])\n",
    "                loss_t = loss.to(\"cpu\").item()\n",
    "                running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "                # compute the accuracy\n",
    "                acc_t = compute_accuracy(y_pred, batch_dict['category'])\n",
    "                running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            self.train_state['val_loss'].append(running_loss)\n",
    "            self.train_state['val_acc'].append(running_acc)\n",
    "\n",
    "            self.train_state = update_train_state(model=self.model, train_state=self.train_state)\n",
    "            self.scheduler.step(self.train_state['val_loss'][-1])\n",
    "            if self.train_state['stop_early']:\n",
    "                break\n",
    "          \n",
    "    def run_test_loop(self):\n",
    "        # initialize batch generator, set loss and acc to 0; set eval mode on\n",
    "        self.dataset.set_split('test')\n",
    "        batch_generator = self.dataset.generate_batches(\n",
    "            batch_size=self.batch_size, shuffle=self.shuffle, device=self.device)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        self.model.eval()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # compute the output\n",
    "            y_pred =  self.model(batch_dict['image'])\n",
    "\n",
    "            # compute the loss\n",
    "            loss = self.loss_func(y_pred, batch_dict['category'])\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['category'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "        self.train_state['test_loss'] = running_loss\n",
    "        self.train_state['test_acc'] = running_acc\n",
    "        \n",
    "        # Verbose\n",
    "        print (\"==> ðŸ’¯ Test performance:\")\n",
    "        print (\"Test loss: {0:.2f}\".format(self.train_state['test_loss']))\n",
    "        print (\"Test Accuracy: {0:.1f}%\".format(self.train_state['test_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(train_state, save_dir, show_plot=True):\n",
    "    \"\"\" Plot loss and accuracy.\n",
    "    \"\"\"\n",
    "    # Figure size\n",
    "    plt.figure(figsize=(15,5))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(train_state[\"train_loss\"], label=\"train\")\n",
    "    plt.plot(train_state[\"val_loss\"], label=\"val\")\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.plot(train_state[\"train_acc\"], label=\"train\")\n",
    "    plt.plot(train_state[\"val_acc\"], label=\"val\")\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    # Save figure\n",
    "    plt.savefig(os.path.join(save_dir, \"performance.png\"))\n",
    "\n",
    "    # Show plots\n",
    "    if show_plot:\n",
    "        print (\"==> ðŸ“ˆ Metric plots:\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_train_state(train_state, save_dir):\n",
    "    train_state[\"done_training\"] = True\n",
    "    with open(os.path.join(save_dir, \"train_state.json\"), \"w\") as fp:\n",
    "        json.dump(train_state, fp)\n",
    "    print (\"==> âœ… Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "trainer = Trainer(\n",
    "    dataset=dataset, model=model, model_file=config[\"model_file\"],\n",
    "    device=config[\"device\"], shuffle=config[\"shuffle\"], \n",
    "    num_epochs=config[\"num_epochs\"], batch_size=config[\"batch_size\"], \n",
    "    learning_rate=config[\"learning_rate\"], \n",
    "    early_stopping_criteria=config[\"early_stopping_criteria\"])\n",
    "trainer.run_train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance\n",
    "plot_performance(train_state=trainer.train_state, \n",
    "                 save_dir=config[\"save_dir\"], show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test performance\n",
    "trainer.run_test_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results\n",
    "save_train_state(train_state=trainer.train_state, save_dir=config[\"save_dir\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "print (model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'vgg19_bn'\n",
    "vgg_19bn = models.__dict__[model_name](pretrained=True) # Set false to train from scratch\n",
    "print (vgg_19bn.named_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageModel(nn.Module):\n",
    "    def __init__(self, feature_extractor, num_hidden_units, \n",
    "                 num_classes, dropout_p):\n",
    "        super(ImageModel, self).__init__()\n",
    "        \n",
    "        # Pretrained feature extractor\n",
    "        self.feature_extractor = feature_extractor\n",
    "        \n",
    "        # FC weights\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 250, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(250, 100, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(100, 10, bias=True),\n",
    "            )\n",
    "\n",
    "    def forward(self, x, apply_softmax=False):\n",
    "          \n",
    "        # Feature extractor\n",
    "        z = self.feature_extractor(x)\n",
    "        z = z.view(x.size(0), -1)\n",
    "        \n",
    "        # FC\n",
    "        y_pred = self.classifier(z)\n",
    "\n",
    "        if apply_softmax:\n",
    "            y_pred = F.softmax(y_pred, dim=1)\n",
    "        return y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(config, vectorizer, feature_extractor):\n",
    "    \"\"\"Initialize the model.\n",
    "    \"\"\"\n",
    "    print (\"\\n==> ðŸš€ Initializing model:\")\n",
    "    model = ImageModel(\n",
    "       feature_extractor=feature_extractor,\n",
    "       num_hidden_units=config[\"fc\"][\"hidden_dim\"], \n",
    "       num_classes=len(vectorizer.category_vocab),\n",
    "       dropout_p=config[\"fc\"][\"dropout_p\"])\n",
    "    print (model.named_modules)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing model\n",
    "model = initialize_model(config=config, vectorizer=vectorizer, \n",
    "                         feature_extractor=vgg_19bn.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetune last few conv layers and FC layers\n",
    "for i, param in enumerate(model.feature_extractor.parameters()):\n",
    "    if i < 36:\n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "trainer = Trainer(\n",
    "    dataset=dataset, model=model, model_file=config[\"model_file\"],\n",
    "    device=config[\"device\"], shuffle=config[\"shuffle\"], \n",
    "    num_epochs=config[\"num_epochs\"], batch_size=config[\"batch_size\"], \n",
    "    learning_rate=config[\"learning_rate\"], \n",
    "    early_stopping_criteria=config[\"early_stopping_criteria\"])\n",
    "trainer.run_train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance\n",
    "plot_performance(train_state=trainer.train_state, \n",
    "                 save_dir=config[\"save_dir\"], show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test performance\n",
    "trainer.run_test_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results\n",
    "save_train_state(train_state=trainer.train_state, save_dir=config[\"save_dir\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 2, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inference(object):\n",
    "    def __init__(self, model, vectorizer, device=\"cpu\"):\n",
    "        self.model = model.to(device)\n",
    "        self.vectorizer = vectorizer\n",
    "        self.device = device\n",
    "  \n",
    "    def predict_category(self, dataset):\n",
    "        # Batch generator\n",
    "        batch_generator = dataset.generate_batches(\n",
    "            batch_size=len(dataset), shuffle=False, device=self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Predict\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # compute the output\n",
    "            y_pred =  self.model(batch_dict['image'], apply_softmax=True)\n",
    "\n",
    "            # Top k categories\n",
    "            y_prob, indices = torch.topk(y_pred, k=len(self.vectorizer.category_vocab))\n",
    "            probabilities = y_prob.detach().to('cpu').numpy()[0]\n",
    "            indices = indices.detach().to('cpu').numpy()[0]\n",
    "\n",
    "            results = []\n",
    "            for probability, index in zip(probabilities, indices):\n",
    "                category = self.vectorizer.category_vocab.lookup_index(index)\n",
    "                results.append({'category': category, 'probability': probability})\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vectorizer\n",
    "with open(config[\"vectorizer_file\"]) as fp:\n",
    "    vectorizer = ImageVectorizer.from_serializable(json.load(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = initialize_model(config=config, vectorizer=vectorizer, feature_extractor=vgg_19bn.features)\n",
    "model.load_state_dict(torch.load(config[\"model_file\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "inference = Inference(model=model, vectorizer=vectorizer, device=config[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample\n",
    "sample = split_df[split_df.split==\"test\"].iloc[0]\n",
    "plt.imshow(sample.image)\n",
    "plt.axis(\"off\")\n",
    "print (\"Actual:\", sample.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "category = list(vectorizer.category_vocab.token_to_idx.keys())[0] # random filler category\n",
    "infer_df = pd.DataFrame([[sample.image, category, \"infer\"]], columns=['image', 'category', 'split'])\n",
    "infer_dataset = ImageDataset(df=infer_df, vectorizer=vectorizer, infer=True)\n",
    "results = inference.predict_category(dataset=infer_dataset)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
